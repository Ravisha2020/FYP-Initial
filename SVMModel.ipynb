{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ7Xh_AangR9",
        "outputId": "23e72bb1-9529-4772-d310-6d71c710048b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn scikit-multilearn\n",
        "!pip install joblib\n",
        "!pip install pyspellchecker\n",
        "!pip install pdf2docx\n",
        "!pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEmwcBdfnjat",
        "outputId": "215de3a5-5fb9-4942-fc79-27e45c3dc13d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pdf2docx in /usr/local/lib/python3.10/dist-packages (0.5.8)\n",
            "Requirement already satisfied: PyMuPDF>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from pdf2docx) (1.23.21)\n",
            "Requirement already satisfied: python-docx>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from pdf2docx) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.10/dist-packages (from pdf2docx) (4.47.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pdf2docx) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5 in /usr/local/lib/python3.10/dist-packages (from pdf2docx) (4.9.0.80)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from pdf2docx) (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->pdf2docx) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.3.0->pdf2docx) (2.4.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.9 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF>=1.19.0->pdf2docx) (1.23.9)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx>=0.8.10->pdf2docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx>=0.8.10->pdf2docx) (4.5.0)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import class_weight\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "\n",
        "# Converts the dataset into a dataframe which represents each category by a separate column\n",
        "def convert_dataset_structure(file_path):\n",
        "    # Loading the dataset from Google Drive\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Splitting the \"Categories\" column and converting each category to lowercase\n",
        "    df['categories'] = df['Categories'].apply(lambda x: [category.strip().strip('\"').lower() for category in x.split(\",\")])\n",
        "\n",
        "    # Removing duplicate categories and sorting the unique categories alphabetically\n",
        "    all_categories = sorted(set(category for categories_list in df['categories'] for category in categories_list))\n",
        "\n",
        "    # Creating a new dataframe which represents each category by a separate column\n",
        "    new_columns = {category: df['categories'].apply(lambda x: 1 if category in x else 0) for category in all_categories}\n",
        "    new_df = pd.concat([df, pd.DataFrame(new_columns)], axis=1)\n",
        "\n",
        "    # Removing the 'Categories' column and the 'categories' column\n",
        "    new_df = new_df.drop(columns=['Categories', 'categories'])\n",
        "\n",
        "    # Shuffling the rows. \"frac=1\" means the entire dataframe will be shuffled\n",
        "    shuffled_df = new_df.sample(frac=1, random_state=42)\n",
        "\n",
        "    # Replacing the last occurrence of \".csv\" in the file path with \"New.csv\"\n",
        "    new_file_path = file_path.rsplit('.csv', 1)[0] + \"New.csv\"\n",
        "\n",
        "    # Storing the converted dataframe in Google Drive using a new file path\n",
        "    shuffled_df.to_csv(new_file_path, index=False, encoding='utf-8')\n",
        "\n",
        "    print(shuffled_df)\n",
        "\n",
        "    return new_file_path\n",
        "\n",
        "# Entering the file path to the original dataset\n",
        "converted_dataset_file_path = convert_dataset_structure('/content/drive/MyDrive/ColabFiles/CategoryDataset1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv_oY0EbLZcM",
        "outputId": "9f0aa945-ddc7-4566-e3b5-3c1c25528275"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Sentence  .net  address  \\\n",
            "229  \"IT consultant providing strategic advice and ...     0        0   \n",
            "73                             \"susan.white@email.com\"     0        0   \n",
            "521                                     \"Apache Kafka\"     0        0   \n",
            "86                                    \"(555) 234-5678\"     0        0   \n",
            "469                                        \"Bootstrap\"     0        0   \n",
            "..                                                 ...   ...      ...   \n",
            "71                                      \"Jacob Miller\"     0        0   \n",
            "106                                  \"(94) 71-8765432\"     0        0   \n",
            "270  \"C# software engineer specializing in developi...     1        0   \n",
            "435  \"Attended a course on Docker and Kubernetes fo...     0        0   \n",
            "102                                  \"(94) 76-9876543\"     0        0   \n",
            "\n",
            "     agile methodologies  ai  algorithms  android  angular  api  apple  ...  \\\n",
            "229                    0   0           0        0        0    0      0  ...   \n",
            "73                     0   0           0        0        0    0      0  ...   \n",
            "521                    0   0           0        0        0    0      0  ...   \n",
            "86                     0   0           0        0        0    0      0  ...   \n",
            "469                    0   0           0        0        0    0      0  ...   \n",
            "..                   ...  ..         ...      ...      ...  ...    ...  ...   \n",
            "71                     0   0           0        0        0    0      0  ...   \n",
            "106                    0   0           0        0        0    0      0  ...   \n",
            "270                    0   0           0        0        0    0      0  ...   \n",
            "435                    0   0           0        0        0    0      0  ...   \n",
            "102                    0   0           0        0        0    0      0  ...   \n",
            "\n",
            "     user interface  vector graphics editor  version control  virtual reality  \\\n",
            "229               0                       0                0                0   \n",
            "73                0                       0                0                0   \n",
            "521               0                       0                0                0   \n",
            "86                0                       0                0                0   \n",
            "469               0                       0                0                0   \n",
            "..              ...                     ...              ...              ...   \n",
            "71                0                       0                0                0   \n",
            "106               0                       0                0                0   \n",
            "270               0                       0                0                0   \n",
            "435               0                       0                0                0   \n",
            "102               0                       0                0                0   \n",
            "\n",
            "     volunteer work  vue  web development  web server  work experience  \\\n",
            "229               0    0                0           0                1   \n",
            "73                0    0                0           0                0   \n",
            "521               0    0                0           0                0   \n",
            "86                0    0                0           0                0   \n",
            "469               0    0                0           0                0   \n",
            "..              ...  ...              ...         ...              ...   \n",
            "71                0    0                0           0                0   \n",
            "106               0    0                0           0                0   \n",
            "270               0    0                0           0                1   \n",
            "435               0    0                0           0                0   \n",
            "102               0    0                0           0                0   \n",
            "\n",
            "     workshops  \n",
            "229          0  \n",
            "73           0  \n",
            "521          0  \n",
            "86           0  \n",
            "469          0  \n",
            "..         ...  \n",
            "71           0  \n",
            "106          0  \n",
            "270          0  \n",
            "435          0  \n",
            "102          0  \n",
            "\n",
            "[540 rows x 151 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the converted dataset from Google Drive\n",
        "df = pd.read_csv(converted_dataset_file_path)\n",
        "\n",
        "print(df.shape)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "SEwtJb7Ing3c",
        "outputId": "04d9e493-30ae-46ab-c742-3f99bb9840ae"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(540, 151)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  .net  address  \\\n",
              "0  \"IT consultant providing strategic advice and ...     0        0   \n",
              "1                            \"susan.white@email.com\"     0        0   \n",
              "2                                     \"Apache Kafka\"     0        0   \n",
              "3                                   \"(555) 234-5678\"     0        0   \n",
              "4                                        \"Bootstrap\"     0        0   \n",
              "\n",
              "   agile methodologies  ai  algorithms  android  angular  api  apple  ...  \\\n",
              "0                    0   0           0        0        0    0      0  ...   \n",
              "1                    0   0           0        0        0    0      0  ...   \n",
              "2                    0   0           0        0        0    0      0  ...   \n",
              "3                    0   0           0        0        0    0      0  ...   \n",
              "4                    0   0           0        0        0    0      0  ...   \n",
              "\n",
              "   user interface  vector graphics editor  version control  virtual reality  \\\n",
              "0               0                       0                0                0   \n",
              "1               0                       0                0                0   \n",
              "2               0                       0                0                0   \n",
              "3               0                       0                0                0   \n",
              "4               0                       0                0                0   \n",
              "\n",
              "   volunteer work  vue  web development  web server  work experience  \\\n",
              "0               0    0                0           0                1   \n",
              "1               0    0                0           0                0   \n",
              "2               0    0                0           0                0   \n",
              "3               0    0                0           0                0   \n",
              "4               0    0                0           0                0   \n",
              "\n",
              "   workshops  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "\n",
              "[5 rows x 151 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c5ead90-e5d2-4e3e-b6f6-a23b5a43354a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>.net</th>\n",
              "      <th>address</th>\n",
              "      <th>agile methodologies</th>\n",
              "      <th>ai</th>\n",
              "      <th>algorithms</th>\n",
              "      <th>android</th>\n",
              "      <th>angular</th>\n",
              "      <th>api</th>\n",
              "      <th>apple</th>\n",
              "      <th>...</th>\n",
              "      <th>user interface</th>\n",
              "      <th>vector graphics editor</th>\n",
              "      <th>version control</th>\n",
              "      <th>virtual reality</th>\n",
              "      <th>volunteer work</th>\n",
              "      <th>vue</th>\n",
              "      <th>web development</th>\n",
              "      <th>web server</th>\n",
              "      <th>work experience</th>\n",
              "      <th>workshops</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"IT consultant providing strategic advice and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"susan.white@email.com\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Apache Kafka\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"(555) 234-5678\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Bootstrap\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 151 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c5ead90-e5d2-4e3e-b6f6-a23b5a43354a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c5ead90-e5d2-4e3e-b6f6-a23b5a43354a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c5ead90-e5d2-4e3e-b6f6-a23b5a43354a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-950c9a46-0832-4f11-8d8c-f363d2190c7c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-950c9a46-0832-4f11-8d8c-f363d2190c7c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-950c9a46-0832-4f11-8d8c-f363d2190c7c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining the 'Sentence' column in the dataset\n",
        "X = df['Sentence']\n",
        "\n",
        "# Obtaining the category columns in the dataset\n",
        "y = df.iloc[:, 1:]\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using TF-IDF to convert text data into numerical vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "tfidf_X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_X_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Trains and evaluates the multi-label text classification model\n",
        "def train_and_evaluate_model():\n",
        "\n",
        "    # Calculating class weights to handle the imbalance in the dataset\n",
        "    class_weights = class_weight.compute_class_weight('balanced', classes=[0, 1], y=y_train.values.flatten())\n",
        "\n",
        "    # Building a multi-label text classification model using BinaryRelevance with SVM\n",
        "    classifier = BinaryRelevance(\n",
        "        classifier=OneVsRestClassifier(SVC(kernel='linear', class_weight={0: class_weights[0], 1: class_weights[1]})),\n",
        "        require_dense=[False, True]\n",
        "    )\n",
        "\n",
        "    # Training the model\n",
        "    classifier.fit(tfidf_X_train, y_train)\n",
        "\n",
        "    # Obtaining predictions of the trained model for the testing set\n",
        "    y_prediction = classifier.predict(tfidf_X_test)\n",
        "\n",
        "    # Displaying the evaluation results of the trained model\n",
        "    print(classification_report(y_test, y_prediction, zero_division=1))\n",
        "\n",
        "    return classifier\n",
        "\n",
        "classifier = train_and_evaluate_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcfgfdFQbGjP",
        "outputId": "dbf81726-ca34-44e4-a1dd-7ee9c49c6a8e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:77: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:77: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:77: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         7\n",
            "           2       1.00      1.00      1.00         0\n",
            "           3       0.00      1.00      0.00         0\n",
            "           4       1.00      1.00      1.00         0\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       1.00      0.00      0.00         2\n",
            "           7       1.00      1.00      1.00         1\n",
            "           8       1.00      0.00      0.00         1\n",
            "           9       1.00      1.00      1.00         1\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       1.00      0.00      0.00         1\n",
            "          12       1.00      1.00      1.00         1\n",
            "          13       1.00      1.00      1.00         0\n",
            "          14       1.00      0.00      0.00         2\n",
            "          15       1.00      0.50      0.67         2\n",
            "          16       1.00      1.00      1.00         0\n",
            "          17       1.00      0.50      0.67         2\n",
            "          18       1.00      1.00      1.00         1\n",
            "          19       1.00      1.00      1.00         0\n",
            "          20       0.00      1.00      0.00         0\n",
            "          21       1.00      0.00      0.00         2\n",
            "          22       0.00      0.00      0.00         2\n",
            "          23       1.00      1.00      1.00         4\n",
            "          24       1.00      1.00      1.00         1\n",
            "          25       1.00      1.00      1.00         0\n",
            "          26       1.00      1.00      1.00         0\n",
            "          27       1.00      0.50      0.67         2\n",
            "          28       0.50      1.00      0.67         1\n",
            "          29       0.67      1.00      0.80         2\n",
            "          30       1.00      1.00      1.00         1\n",
            "          31       1.00      1.00      1.00         1\n",
            "          32       1.00      0.95      0.97        19\n",
            "          33       1.00      1.00      1.00         2\n",
            "          34       1.00      1.00      1.00         0\n",
            "          35       0.67      1.00      0.80         2\n",
            "          36       1.00      0.00      0.00         1\n",
            "          37       1.00      0.50      0.67         2\n",
            "          38       1.00      0.33      0.50         3\n",
            "          39       0.00      0.00      0.00         4\n",
            "          40       1.00      0.00      0.00         1\n",
            "          41       0.50      1.00      0.67         1\n",
            "          42       1.00      1.00      1.00         1\n",
            "          43       1.00      1.00      1.00        12\n",
            "          44       1.00      0.50      0.67         2\n",
            "          45       1.00      1.00      1.00         0\n",
            "          46       1.00      0.33      0.50         3\n",
            "          47       1.00      1.00      1.00         0\n",
            "          48       1.00      0.00      0.00         1\n",
            "          49       1.00      1.00      1.00         0\n",
            "          50       1.00      1.00      1.00         0\n",
            "          51       0.93      0.82      0.87        17\n",
            "          52       1.00      1.00      1.00         8\n",
            "          53       1.00      1.00      1.00         0\n",
            "          54       1.00      0.00      0.00         1\n",
            "          55       0.00      0.00      0.00         1\n",
            "          56       0.00      1.00      0.00         0\n",
            "          57       0.00      1.00      0.00         0\n",
            "          58       0.67      0.67      0.67         3\n",
            "          59       1.00      1.00      1.00         0\n",
            "          60       1.00      1.00      1.00         0\n",
            "          61       1.00      1.00      1.00         0\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       0.00      1.00      0.00         0\n",
            "          64       0.60      0.50      0.55        12\n",
            "          65       0.50      0.50      0.50         2\n",
            "          66       1.00      0.00      0.00         1\n",
            "          67       1.00      0.50      0.67         2\n",
            "          68       1.00      0.75      0.86         4\n",
            "          69       1.00      1.00      1.00         1\n",
            "          70       1.00      1.00      1.00         2\n",
            "          71       1.00      1.00      1.00         1\n",
            "          72       1.00      1.00      1.00         0\n",
            "          73       0.80      0.67      0.73         6\n",
            "          74       0.50      1.00      0.67         1\n",
            "          75       1.00      1.00      1.00         0\n",
            "          76       1.00      1.00      1.00         0\n",
            "          77       1.00      0.50      0.67         2\n",
            "          78       0.00      0.00      0.00         3\n",
            "          79       1.00      0.00      0.00         1\n",
            "          80       1.00      0.00      0.00         1\n",
            "          81       1.00      0.00      0.00         3\n",
            "          82       1.00      1.00      1.00         0\n",
            "          83       1.00      0.00      0.00         3\n",
            "          84       1.00      0.00      0.00         1\n",
            "          85       1.00      0.00      0.00         1\n",
            "          86       1.00      1.00      1.00         0\n",
            "          87       1.00      0.57      0.73         7\n",
            "          88       1.00      1.00      1.00         1\n",
            "          89       1.00      1.00      1.00         0\n",
            "          90       1.00      0.44      0.62         9\n",
            "          91       1.00      1.00      1.00         0\n",
            "          92       1.00      1.00      1.00         1\n",
            "          93       1.00      1.00      1.00         0\n",
            "          94       1.00      1.00      1.00         0\n",
            "          95       1.00      1.00      1.00         0\n",
            "          96       0.50      0.25      0.33         4\n",
            "          97       1.00      1.00      1.00         0\n",
            "          98       1.00      0.79      0.88        24\n",
            "          99       1.00      0.91      0.95        11\n",
            "         100       1.00      1.00      1.00         0\n",
            "         101       1.00      0.00      0.00         1\n",
            "         102       1.00      1.00      1.00         0\n",
            "         103       1.00      1.00      1.00         0\n",
            "         104       1.00      1.00      1.00         0\n",
            "         105       1.00      0.40      0.57         5\n",
            "         106       1.00      0.50      0.67         2\n",
            "         107       1.00      0.00      0.00         1\n",
            "         108       1.00      1.00      1.00         0\n",
            "         109       1.00      0.33      0.50         3\n",
            "         110       1.00      0.00      0.00         2\n",
            "         111       1.00      0.00      0.00         1\n",
            "         112       1.00      1.00      1.00         0\n",
            "         113       1.00      0.00      0.00         1\n",
            "         114       1.00      1.00      1.00         7\n",
            "         115       1.00      1.00      1.00         1\n",
            "         116       1.00      1.00      1.00         1\n",
            "         117       1.00      0.50      0.67         2\n",
            "         118       1.00      1.00      1.00         0\n",
            "         119       1.00      1.00      1.00         0\n",
            "         120       1.00      1.00      1.00         0\n",
            "         121       1.00      1.00      1.00         0\n",
            "         122       1.00      0.00      0.00         1\n",
            "         123       1.00      1.00      1.00         1\n",
            "         124       1.00      0.50      0.67         4\n",
            "         125       1.00      0.00      0.00         2\n",
            "         126       1.00      0.00      0.00         1\n",
            "         127       0.55      1.00      0.71        24\n",
            "         128       1.00      0.00      0.00         1\n",
            "         129       0.00      0.00      0.00         2\n",
            "         130       1.00      0.00      0.00         1\n",
            "         131       1.00      1.00      1.00         1\n",
            "         132       0.00      1.00      0.00         0\n",
            "         133       1.00      1.00      1.00         0\n",
            "         134       1.00      1.00      1.00         1\n",
            "         135       1.00      0.00      0.00         1\n",
            "         136       1.00      0.00      0.00         1\n",
            "         137       1.00      0.00      0.00         2\n",
            "         138       1.00      0.50      0.67         2\n",
            "         139       1.00      1.00      1.00         0\n",
            "         140       0.50      1.00      0.67         1\n",
            "         141       0.00      1.00      0.00         0\n",
            "         142       1.00      0.00      0.00         2\n",
            "         143       1.00      1.00      1.00         1\n",
            "         144       1.00      0.50      0.67         2\n",
            "         145       1.00      1.00      1.00         0\n",
            "         146       0.40      0.67      0.50         3\n",
            "         147       0.50      1.00      0.67         1\n",
            "         148       0.93      0.98      0.95        43\n",
            "         149       1.00      1.00      1.00         0\n",
            "\n",
            "   micro avg       0.81      0.69      0.75       356\n",
            "   macro avg       0.88      0.68      0.64       356\n",
            "weighted avg       0.88      0.69      0.71       356\n",
            " samples avg       0.74      0.66      0.67       356\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the prediction of the multi-label text classification model for a given sentence\n",
        "def predict_categories(sentence, threshold):\n",
        "    # Converting the sentence to TF-IDF representation\n",
        "    tfidf_sentence = tfidf_vectorizer.transform([sentence])\n",
        "\n",
        "    # Initializing an empty dataframe to store prediction scores\n",
        "    sentence_prediction_scores = pd.DataFrame(columns=y.columns)\n",
        "\n",
        "    # Iterating through each label to get prediction scores\n",
        "    for label in range(y.shape[1]):\n",
        "        # Getting prediction scores for the sentence\n",
        "        label_prediction_score = classifier.classifiers_[label].decision_function(tfidf_sentence)\n",
        "\n",
        "        # Adding the prediction scores to the dataframe\n",
        "        sentence_prediction_scores[y.columns[label]] = label_prediction_score\n",
        "\n",
        "    # Calculating prediction scores between 0 and 1\n",
        "    sentence_prediction_scores = 1 / (1 + 10**(-sentence_prediction_scores))\n",
        "\n",
        "    # Getting binary predictions for the sentence\n",
        "    sentence_prediction = (sentence_prediction_scores > threshold).astype(int)\n",
        "\n",
        "    # Modifying the prediction dataframe for better readability\n",
        "    sentence_prediction_table = sentence_prediction_scores.melt(var_name='Label', value_name='Prediction Score')\n",
        "\n",
        "    # Concatenating binary predictions to the dataframe\n",
        "    sentence_prediction_table['Prediction'] = sentence_prediction.values.flatten()\n",
        "\n",
        "    # Obtaining the rows with a prediction score higher than the specified threshold\n",
        "    sentence_prediction_table = sentence_prediction_table[sentence_prediction_table['Prediction Score'] > threshold]\n",
        "\n",
        "    return sentence_prediction_table\n",
        "\n",
        "# Getting predictions for a sample sentence\n",
        "sample_sentence = \"Mobile application developer who is holding a degree in Mobile Application Development with a proficiency in Kotlin and Swift.\"\n",
        "sample_prediction = predict_categories(sample_sentence, 0.5)\n",
        "\n",
        "print(\"Predictions for the sentence:\")\n",
        "print(sample_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txJED3vgdK5H",
        "outputId": "4167d9e8-1328-45eb-b563-0e08099f416b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for the sentence:\n",
            "                    Label  Prediction Score  Prediction\n",
            "43                 degree          0.760221           1\n",
            "51              education          0.884699           1\n",
            "75                 kotlin          0.671074           1\n",
            "87                 mobile          0.934070           1\n",
            "127  software development          0.968874           1\n",
            "129                 swift          0.505115           1\n",
            "148       work experience          0.900891           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Saves the trained model\n",
        "def save_model(classifier):\n",
        "    # Saving the trained model to Google Drive\n",
        "    model_filename = '/content/drive/MyDrive/ColabFiles/multi_label_classifier_model.joblib'\n",
        "    joblib.dump(classifier, model_filename)\n",
        "\n",
        "save_model(classifier)"
      ],
      "metadata": {
        "id": "fUNhm6XSOg8X"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "# Corrects the spellings of text inputs\n",
        "def spell_correction(text_input):\n",
        "    spell = SpellChecker()\n",
        "    # Removing the leading and trailing whitespaces in the text input\n",
        "    misspelled = text_input.split()\n",
        "\n",
        "    corrected_term = \"\"\n",
        "\n",
        "    for word in misspelled:\n",
        "        # Getting the most likely word\n",
        "        corrected_word = spell.correction(word)\n",
        "\n",
        "        if corrected_word is None and (word.lower() != \"none\" and word.lower() != \"non\"):\n",
        "            return \"cannot recognize word\"\n",
        "\n",
        "        else:\n",
        "            corrected_term += f\"{corrected_word} \"\n",
        "\n",
        "    return corrected_term.strip()"
      ],
      "metadata": {
        "id": "C900crtCPIKS"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Areas of interest entered by the user\n",
        "areas_of_interest = [\"work exprience\", \"degree\", \"edcation\", \"vbvjhsfbfhjsbv\"]\n",
        "\n",
        "# Corrects the spellings of the areas of interest entered by the user\n",
        "def areas_of_interest_correct_spellings(areas_of_interests):\n",
        "    corrected_areas_of_interest = []\n",
        "    for area in areas_of_interests:\n",
        "        corrected_term = spell_correction(area)\n",
        "        if corrected_term != \"cannot recognize word\":\n",
        "            corrected_areas_of_interest.append(corrected_term)\n",
        "        print(corrected_term)\n",
        "\n",
        "    return corrected_areas_of_interest\n",
        "\n",
        "corrected_areas_of_interest = areas_of_interest_correct_spellings(areas_of_interest)\n",
        "\n",
        "print(corrected_areas_of_interest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDsiQbWwQh53",
        "outputId": "6a419c14-b4a2-4e6f-da5a-926e1c4a58cc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work experience\n",
            "degree\n",
            "education\n",
            "cannot recognize word\n",
            "['work experience', 'degree', 'education']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2docx import Converter\n",
        "\n",
        "# Resume uploaded by the user\n",
        "uploaded_resume = '/content/drive/MyDrive/ColabFiles/10089434.pdf'\n",
        "\n",
        "# Converts a '.pdf' file to a '.docx' file\n",
        "def convert_pdf_to_docx(pdf_path):\n",
        "    if pdf_path.endswith('.pdf'):\n",
        "        # Replacing '.pdf' in the pdf path string with '.docx'\n",
        "        docx_path = pdf_path[:-3] + 'docx'\n",
        "\n",
        "        # Converting the '.pdf' file to a '.docx' file\n",
        "        cv = Converter(pdf_path)\n",
        "\n",
        "        # Storing the converted '.docx' file in the docx path\n",
        "        cv.convert(docx_path)\n",
        "        cv.close()\n",
        "\n",
        "        return docx_path\n",
        "\n",
        "    print(\"The file does not contain a '.pdf' extension.\")\n",
        "\n",
        "    return None\n",
        "\n",
        "uploaded_resume_to_docx = convert_pdf_to_docx(uploaded_resume)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BEqmrmaQwiT",
        "outputId": "da3581c2-d3cd-403d-8ec7-10b2142ae8d7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fontTools.ttLib.tables._h_e_a_d:'created' timestamp seems very low; regarding as unix timestamp\n",
            "WARNING:fontTools.ttLib.tables._h_e_a_d:'modified' timestamp seems very low; regarding as unix timestamp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "\n",
        "# Converts a '.docx' file to plain text\n",
        "def extract_text_from_docx(docx_path):\n",
        "    if docx_path.endswith('.docx'):\n",
        "        # Converting the '.docx' file to plain text\n",
        "        txt = docx2txt.process(docx_path)\n",
        "        if txt:\n",
        "            # Replacing the tabs in the text with a space\n",
        "            tabs_replaced = txt.replace('\\t', ' ')\n",
        "\n",
        "            # Replacing the additional line breaks in the text with a single line break\n",
        "            line_breaks_replaced = tabs_replaced.replace('\\n\\n', '\\n').replace('\\n\\n\\n', '\\n')\n",
        "\n",
        "            return line_breaks_replaced\n",
        "\n",
        "    print(\"The file does not contain a '.docx' extension.\")\n",
        "\n",
        "    return None\n",
        "\n",
        "resume_text = extract_text_from_docx(uploaded_resume_to_docx)\n",
        "\n",
        "print(resume_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvwl5q5zQ5Ag",
        "outputId": "71f6f56d-881b-43c3-d844-2086cbcea568"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFORMATION TECHNOLOGY TECHNICIAN I \n",
            "Summary\n",
            "Versatile Systems Administrator possessing superior troubleshooting skills for networking issues, end user problems, and network security. Experienced in server management, systems analysis, and offering in-depth understanding of IT infrastructure areas. Detail-oriented, independent, and focused on taking a systematic approach to solving complex problems. Demonstrated exceptional technical knowledge and skills while working with various teams to achieve shared goals and objectives.\n",
            "Highlights\n",
            "Active Directory \n",
            "Group Policy Objects \n",
            "PowerShell and VBScript Microsoft Exchange \n",
            "VMWare experience\n",
            "New technology and product research Office 365 and Azure \n",
            "Storage management \n",
            "Enterprise backup management \n",
            "Disaster recovery\n",
            "Experience \n",
            "Information Technology Technician I Aug 2007 to Current \n",
            "Company Name Ã¯Â¼â€‹ City , State\n",
            "Migrating and managing user accounts in Microsoft Office 365 and Exchange Online.\n",
            "Creating and managing virtual machines for systems such as domain controllers and Active Directory Federation Services (ADFS) in Microsoft Windows Azure (IaaS).\n",
            "Creating and managing storage in Microsoft Windows Azure (IaaS).\n",
            "Installing and configuring StorSimple iSCSI cloud array (STaaS/BaaS).\n",
            "Installing, configuring, and testing Twinstrata iSCSI cloud array (STaaS/BaaS).\n",
            "Collaborating on project plan for Office 365 migration.\n",
            "Developing detailed specifications for the Office 365 migration, including business-case documentation, cost benefit analyses, technical diagrams, and work flow documentation.\n",
            "Received training in MVC 4 for Visual Studio using .Net Framework 4/4.5 to develop application using HTML5 and CSS3.\n",
            "Installing, configuring, and supporting Linux machines for the open Wi-Fi network project.\n",
            "Compiling and generating statistical information concerning wireless network traffic using Cacti.\n",
            "Configuring wireless LAN router networking and security access.\n",
            "Installing and configuring wireless certificates.\n",
            "Developing detailed specifications for the acquisition of an Enterprise backup system including systems design, business-case documentation, cost benefit analysis, technical diagrams, and work flow documentation.\n",
            "Reviewing, evaluating, and analyzing departmental policies, guidelines, procedures, and standards with management and staff.\n",
            "Developing test scripts for acceptance, unit, and system testing of Hyperion Phase 1 and MiamiBiz Phase 2.\n",
            "Developing Quality Assurance and testing plan for Hyperion Phase 1 and MiamiBiz Phase 2.\n",
            "Debugging and logging of errors in Hyperion and MiamiBiz using Team Foundation Server (TFS).\n",
            "Participated in various phases of the project life cycle such as: determining requirements, design conceptualization, testing, implementation, deployment, and release for the Hyperion and MiamiBiz projects.\n",
            "Collaborating on project plans for Hyperion and MiamiBiz.\n",
            "Preparing presentations and documentation to demonstrate Hyperion and MiamiBiz functionality or design.\n",
            "Monitoring network traffic, and compiling and generating statistical information using Solar Winds.\n",
            "Collaborating on Disaster Recovery plan and procedures.\n",
            "Researching, evaluating, and recommending new hardware and new software.\n",
            "Communicating and defining systems design and requirements for new and existing systems and applications.\n",
            "Researching, evaluating, recommending, testing, and implementing third party software/utilities.\n",
            "Planning and designing network infrastructure changes Ã¢â‚¬â€œ adding/removing servers, appliances, network logical flow.\n",
            "Reviewing, evaluating, and analyzing existing system and application viability with management and staff.\n",
            "Administering and maintaining shares on the file servers.\n",
            "Reviewing server logs to troubleshoot issues.\n",
            "Scheduling and applying hot fixes and security patches on the server infrastructure which includes the operating system and application software.\n",
            "Reviewing systems reporting in SCCM (System Center Configuration Manager).\n",
            "Resolving service requests escalated by the Help Desk or other technicians.\n",
            "Troubleshooting and analyzing and system problems for root cause analysis.\n",
            "Giving and participating in training and education programs to explain upgrades to end users.\n",
            "Migrating users' documents from local computer storage to shares on the file servers.\n",
            "Configuring, supporting, and maintaining file shares using Distributed File System (DFS) \n",
            "Managing, implementing, and testing Enterprise backup infrastructure systems such as the Symantec Veritas Netbackup, Symantec Backup Exec System Recovery/Livestate, and VRanger backup servers.\n",
            "Managing, configuring, and supporting DataDomain storage.\n",
            "Configuring and supporting Microsoft Windows Server 2003, 2008, and 2012.\n",
            "Installing, configuring, and supporting Microsoft Windows 7, Windows 8, and Microsoft Office 2007, 2010, and 2013.\n",
            "Installing, configuring, and supporting McAfee anti-virus software on servers.\n",
            " Migrating Exchange infrastructure from Exchange 2003 to Exchange 2007 and from Exchange 2007 to Exchange 2010. Supporting servers in the virtualization infrastructure using VMware vSphere.\n",
            "Installing, configuring, and testing Veeam virtual machine backup software and Virtual Desktop Infrastructure (VDI).\n",
            " Reviewing systems reporting in System Center Configuration Manager (SCCM). Administering and maintaining the Symantec Enterprise Vault servers. \n",
            "Managing the Active Directory Domain Controllers (DCs).\n",
            " Creating and maintaining Group Policy Objects (GPOs) in Microsoft Active Directory.\n",
            "Configuring and supporting Microsoft Exchange Active Sync on devices with Apple iOS and Android mobile operating systems. Configuring and supporting Blackberry devices on the Blackberry Enterprise Server to receive Exchange email.\n",
            " Developing, testing, designing, and implementing application scripts using languages such as command batch files, Visual Basic Script, and PowerShell.\n",
            "Creating policies and procedural documentation.\n",
            "Information Services Liaison, T Aug 2005 to Aug 2007 \n",
            "Company Name Ã¯Â¼â€‹ City , State\n",
            "Troubleshooting hardware and software problems over the telephone and through remote PC administration software.\n",
            "Installing, configuring, and supporting McAfee anti-virus software on desktops.\n",
            "Installing, configuring, and supporting BBars computer backup software.\n",
            "Developing and maintaining websites on servers running Microsoft SharePoint Server and Internet Information Services (IIS).\n",
            "Supporting Systems Management Server (SMS) \n",
            "Troubleshooting LAN, WAN, Internet, and Intranet network and security access.\n",
            "Troubleshooting network connectivity issues related to TCP/IP, Domain Name Service (DNS), Dynamic Host Configuration Protocol (DHCP) protocols, Internet Security and Acceleration (ISA) proxy server, and VPN.\n",
            "Troubleshooting web application/page issues, client browsers, and related software.\n",
            "Administering and maintaining of end user accounts, permissions, and access rights in in Microsoft Active Directory.\n",
            "Administering and maintaining of NTFS security permissions on the file servers.\n",
            "Installing, configuring, and maintaining hardware such as: servers, workstations, laptops, printers, and scanners in a Windows Enterprise environment.\n",
            "Installing, configuring, and supporting printers on the print servers.\n",
            "Installing, configuring, and supporting Microsoft Windows Server 2000 and 2003, Microsoft Windows XP and Windows Vista, and Microsoft Office XP, 2003, and 2007.\n",
            "Education \n",
            "Bachelor of Science , Information Technology 2005 Florida International Univeristy Ã¯Â¼â€‹ City , State , United States\n",
            "Coursework in Programming, Web Administration, Network Administration, Database Administration, and Systems Administration Ã¢â‚¬â€œLinux \n",
            "Programming Languages: C++, Java, JSP, HTML, CSS, VB.Net, Bash, T-SQL\n",
            "Certifications\n",
            "CompTIA Network+ - 2014\n",
            "Skills\n",
            "Active Directory, Azure, anti-virus, Backup Exec, backup, Bash, batch, Cacti, Cisco ASA, databases, DHCP, DNS, documentation, DataDomain, EMC, Enterprise Vault, ePO, file servers, firewall, GPO, HTML, IIS, ISA, LDAP, Linux, McAfee, Exchange, Microsoft Office, Microsoft Windows, security, policies, PowerShell, programming, proxy server, servers, scripts, SolarWinds, SQL, StorSimple, troubleshooting, TMG, Ubuntu, Visual Basic Script, VBS, Veritas Netbackup, VPN, VRanger, Veeam, VMWare, VDI, virtual manchine, NMap, ZenMap.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Loading the BERT model and the BERT tokenizer\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Checks the similarity of the category and the area of interest\n",
        "def check_similarity(category, area_of_interest):\n",
        "  # Tokenizing the two text inputs\n",
        "  category_tokens = bert_tokenizer(category, return_tensors='pt')\n",
        "  area_of_interest_tokens = bert_tokenizer(area_of_interest, return_tensors='pt')\n",
        "\n",
        "  # Obtaining embeddings for the tokenized text inputs by disabling gradient computation\n",
        "  with torch.no_grad():\n",
        "      category_embeddings = bert_model(**category_tokens).last_hidden_state.mean(dim=1).numpy()\n",
        "      area_of_interest_embeddings = bert_model(**area_of_interest_tokens).last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "  # Calculating the similarity between the two embeddings\n",
        "  similarity_of_input_text = np.dot(category_embeddings, area_of_interest_embeddings.T) / (np.linalg.norm(category_embeddings) * np.linalg.norm(area_of_interest_embeddings))\n",
        "\n",
        "  return similarity_of_input_text[0][0]"
      ],
      "metadata": {
        "id": "IirQTgcqRyxO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_threshold = 0.8\n",
        "similarity_threshold = 0.9\n",
        "sentence_category_mapping = [] # Sentences in the resume with their predicted categories\n",
        "identified_categories = [] # Categories found in the resume\n",
        "category_relevance = [] # Similarity between each category found and each area of interest\n",
        "relevant_categories = [] # Categoryies which match with at least one area of interest\n",
        "relevant_sentences = [] # Sentences which belong to categories which match with at least one area of interest\n",
        "\n",
        "# Predicts the categories of each sentence in the resume\n",
        "def predict_resume_sentence_categories(sentences):\n",
        "    for sentence in sentences:\n",
        "        predictions = predict_categories(sentence, prediction_threshold)\n",
        "        for index, row in predictions.iterrows():\n",
        "            label = row['Label']\n",
        "            prediction_score = row['Prediction Score']\n",
        "            if prediction_score > prediction_threshold:\n",
        "                sentence_category_mapping.append([sentence, label, prediction_score])\n",
        "                if label not in identified_categories:\n",
        "                    identified_categories.append(label)\n",
        "\n",
        "# Checks the similarity between the identified categories and the areas of interest\n",
        "def check_relevance_of_categories(areas_of_interest):\n",
        "    for category in identified_categories:\n",
        "        for area_of_interest in areas_of_interest:\n",
        "            similarity = check_similarity(category, area_of_interest)\n",
        "            if similarity > similarity_threshold:\n",
        "                category_relevance.append([category, area_of_interest, similarity])\n",
        "                if category not in relevant_categories:\n",
        "                    relevant_categories.append(category)\n",
        "\n",
        "# Joins the relevant sentences into a paragraph to form the summary\n",
        "def join_relevant_sentences():\n",
        "    summary = \"\"\n",
        "\n",
        "    for sentence in relevant_sentences:\n",
        "        # Adding a full stop to all the sentences ending without a full stop\n",
        "        if sentence.strip().endswith('.'):\n",
        "            summary += sentence + \" \"\n",
        "        else:\n",
        "            summary += sentence + \". \"\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Summarizes the uploaded resume based on the entered areas of interest\n",
        "def summarize_resume(resume_text, areas_of_interest):\n",
        "    # Splitting the resume text at each line break to form an array of sentences\n",
        "    sentences = [sentence.strip() for sentence in resume_text.split('\\n') if sentence.strip()]\n",
        "\n",
        "    predict_resume_sentence_categories(sentences)\n",
        "\n",
        "    check_relevance_of_categories(areas_of_interest)\n",
        "\n",
        "    # Obtaining the sentences which belong to categories which are relevant to the areas of interest\n",
        "    for mapping in sentence_category_mapping:\n",
        "        if mapping[0] not in relevant_sentences and mapping[1] in relevant_categories:\n",
        "            relevant_sentences.append(mapping[0])\n",
        "\n",
        "    if not relevant_sentences:\n",
        "        return \"Relevant data could not be found in the resume.\"\n",
        "\n",
        "    summary = join_relevant_sentences()\n",
        "\n",
        "    return summary\n",
        "\n",
        "result = summarize_resume(resume_text, corrected_areas_of_interest)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKmqgnTiTwes",
        "outputId": "efd39095-940d-4328-c926-1ce39383672f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFORMATION TECHNOLOGY TECHNICIAN I. Versatile Systems Administrator possessing superior troubleshooting skills for networking issues, end user problems, and network security. Experienced in server management, systems analysis, and offering in-depth understanding of IT infrastructure areas. Detail-oriented, independent, and focused on taking a systematic approach to solving complex problems. Demonstrated exceptional technical knowledge and skills while working with various teams to achieve shared goals and objectives. VMWare experience. New technology and product research Office 365 and Azure. Experience. Information Technology Technician I Aug 2007 to Current. Developing detailed specifications for the acquisition of an Enterprise backup system including systems design, business-case documentation, cost benefit analysis, technical diagrams, and work flow documentation. Debugging and logging of errors in Hyperion and MiamiBiz using Team Foundation Server (TFS). Communicating and defining systems design and requirements for new and existing systems and applications. Scheduling and applying hot fixes and security patches on the server infrastructure which includes the operating system and application software. Configuring, supporting, and maintaining file shares using Distributed File System (DFS). Managing, implementing, and testing Enterprise backup infrastructure systems such as the Symantec Veritas Netbackup, Symantec Backup Exec System Recovery/Livestate, and VRanger backup servers. Reviewing systems reporting in System Center Configuration Manager (SCCM). Administering and maintaining the Symantec Enterprise Vault servers. Developing, testing, designing, and implementing application scripts using languages such as command batch files, Visual Basic Script, and PowerShell. Supporting Systems Management Server (SMS). Troubleshooting LAN, WAN, Internet, and Intranet network and security access. Bachelor of Science , Information Technology 2005 Florida International Univeristy Ã¯Â¼â€‹ City , State , United States. \n"
          ]
        }
      ]
    }
  ]
}